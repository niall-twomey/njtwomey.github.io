<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Niall Twomey</title>
  <meta name="description" content="A website for cataloguing publications, projects, code snippets.">

  <link rel="shortcut icon" href="http://localhost:4000/assets/img/favicon.ico">
  <link rel="icon" href="http://localhost:4000/assets/img/favicon.ico">
  <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
  <link rel="canonical" href="http://localhost:4000/blog/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <span class="site-title">
        
        <a href='/'><strong>Niall</strong> Twomey</a>
    </span>

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="http://localhost:4000/">about</a>

        <!-- Blog -->
        <a class="page-link" href="http://localhost:4000/blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="http://localhost:4000/projects/">projects</a>
          
        
          
            <a class="page-link" href="http://localhost:4000/publications/">publications</a>
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="http://localhost:4000/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="header-bar">
  <h2>Notes, snippets and articles!</h2>
  <h3></h3>
</div>

<ul class="post-list">
  
    
    <li>
      <h2><a class="post-title" href="/blog/2019/svfm/">Neural ODEs with stochastic vector field mixtures</a></h2>
      <p class="post-meta">May 23, 2019</p>
      <div class="profile col one left">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2019/svfm/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2019/svfm/thumb.png" />
  </a>
</div>



        
      </div>
      <p>It was recently shown that neural ordinary differential equation models cannot solve fundamental and seemingly straightforward tasks even with high-capacity vector field representations. This paper introduces two other fundamental tasks to the set that baseline methods cannot solve, and proposes mixtures of stochastic vector fields as a model class that is capable of solving these essential problems. Dynamic vector field selection is of critical importance for our model, and our approach is to propagate component uncertainty over the integration interval with a technique based on forward filtering. We also formalise several loss functions that encourage desirable properties on the trajectory paths, and of particular interest are those that directly encourage fewer expected function evaluations. Experimentally, we demonstrate that our model class is capable of capturing the natural dynamics of human behaviour; a notoriously volatile application area. Baseline approaches cannot adequately model this problem.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2019/storm/">Ordinal regression as structured classification</a></h2>
      <p class="post-meta">May 20, 2019</p>
      <div class="profile col one right">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2019/storm/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2019/storm/thumb.png" />
  </a>
</div>



        
      </div>
      <p>This paper extends the class of ordinal regression models with a structured interpretation of the problem by applying a novel treatment of encoded labels. The net effect of this is to transform the underlying problem from an ordinal regression task to a (structured) classification task which we solve with conditional random fields, thereby achieving a coherent and probabilistic model in which all model parameters are jointly learnt. Importantly, we show that although we have cast ordinal regression to classification, our method still fall within the class of decomposition methods in the ordinal regression ontology. This is an important link since our experience is that many applications of machine learning to healthcare ignores completely the important nature of the label ordering, and hence these approaches should considered naive in this ontology. We also show that our model is flexible both in how it adapts to data manifolds and in terms of the operations that are available for practitioner to execute. Our empirical evaluation demonstrates that the proposed approach overwhelmingly produces superior and often statistically significant results over baseline approaches on forty popular ordinal regression models, and demonstrate that the proposed model significantly out-performs baselines on synthetic and real datasets. Our implementation, together with scripts to reproduce the results of this work, will be available on a public GitHub repository.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2019/allp/">Active Learning with Label Proportions</a></h2>
      <p class="post-meta">May 12, 2019</p>
      <div class="profile col one left">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2019/allp/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2019/allp/thumb.png" />
  </a>
</div>



        
      </div>
      <p>Active Learning (AL) refers to the setting where the learner has the ability to perform queries to an oracle to acquire the true label of an instance or, sometimes, a set of instances. Even though Active Learning has been studied extensively, the setting is usually restricted to assume that the oracle is trustworthy and will provide the actual label. We argue that, while common, this approach can be made more flexible to account for different forms of supervision. In this paper, we propose a new framework that allows the algorithm to request the label for a bag of samples at a time. Although this label will come in the form of proportions of class labels in the bags and therefore encode less information, we demonstrate that we can still learn effectively.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2019/hgpad-journal/">An application of hierarchical Gaussian processes to the detection of anomalies in star light curves</a></h2>
      <p class="post-meta">February 4, 2019</p>
      <div class="profile col one right">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2019/hgpad-journal/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2019/hgpad-journal/thumb.png" />
  </a>
</div>



        
      </div>
      <p>This study is concerned with astronomical time-series called light-curves that represent the brightness of celestial objects over a period of time. We consider the task of finding anomalous light-curves of periodic variable stars. We employ a Hierarchical Gaussian Process to create a general and stable model of time-series for anomaly detection, and apply this approach to the light-curve problem. Hierarchical Gaussian Processes require only a few additional parameters compared to conventional Gaussian Processes and incur negligible additional computational complexity. Moreover, since the additional parameters are objectively optimised in a principled probabilistic framework one does not need to resort to grid searches for parameter selection. Experimentally, we demonstrate that our approach outperforms several baselines on both synthetic and light-curve data. Of particular interest is that the proposed method generalises very well from small subsets of the data, achieving near perfect precision of outlier detection even with as few as seven instances.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2018/lpllp/">Label Propagation for Learning with Label Proportions</a></h2>
      <p class="post-meta">September 17, 2018</p>
      <div class="profile col one left">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2018/lpllp/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2018/lpllp/thumb.png" />
  </a>
</div>



        
      </div>
      <p>Learning with Label Proportions (LLP) is the problem of recovering the underlying true labels given a dataset when the data is presented in the form of bags. This paradigm is particularly suitable in contexts where providing individual labels is expensive and label aggregates are more easily obtained. In the healthcare domain, it is a burden for a patient to keep a detailed diary of their daily routines, but often they will be amenable to provide higher level summaries of daily behavior. We present a novel and efficient graph-based algorithm that encourages local smoothness and exploits the global structure of the data, while preserving the â€˜massâ€™ of each bag.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2018/releasing/">Releasing eHealth Analytics into the Wild: Lessons Learnt from the SPHERE Project</a></h2>
      <p class="post-meta">July 19, 2018</p>
      <div class="profile col one right">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2018/releasing/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2018/releasing/thumb.png" />
  </a>
</div>



        
      </div>
      <p>The SPHERE project is devoted to advancing eHealth in a smart-home context, and supports full-scale sensing and data analysis to enable a generic healthcare service. We describe, from a data-science perspective, our experience of taking the system out of the laboratory into more than thirty homes in Bristol, UK. We describe the infrastructure and processes that had to be developed along the way, describe how we train and deploy Machine Learning systems in this context, and give a realistic appraisal of the state of the deployed systems.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2018/guide/">A Guide to the SPHERE 100 Homes Study Dataset</a></h2>
      <p class="post-meta">May 30, 2018</p>
      <div class="profile col one left">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2018/guide/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2018/guide/thumb.png" />
  </a>
</div>



        
      </div>
      <p>The SPHERE project has developed a multi-modal sensor platform for health and behavior monitoring in residential environments. So far, the SPHERE platform has been deployed for data collection in approximately 50 homes for duration up to one year. This technical document describes the format and the expected content of the SPHERE dataset (s) under preparation. It includes a list of some data quality problems (both known to exist in the dataset (s) and potential ones), their workarounds, and other information important to people working with the SPHERE data, software, and hardware. This document does not aim to be an exhaustive descriptor of the SPHERE dataset (s); it also does not aim to discuss or validate the potential scientific uses of the SPHERE data.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2018/efficient/">Efficient Approximate Representations of Computationally Expensive Features</a></h2>
      <p class="post-meta">April 1, 2018</p>
      <div class="profile col one right">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2018/efficient/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2018/efficient/thumb.png" />
  </a>
</div>



        
      </div>
      <p>High computational complexity is often a barrier to achieving desired representations in resource-constrained settings. This paper introduces a simple and computationally cheap method of approximating complex features. We do so by carefully constraining the architecture of Neural Networks (NNs) and regress from raw data to the intended feature representation. Our analysis focuses on spectral features, and demonstrates how low-capacity networks can capture the end-to-end dynamics of cascaded composite functions. Not only do approximating NNs simplify the analysis pipeline, but our approach produces feature representations up to 20 times more quickly. Excellent feature fidelity is achieved in our experimental analysis with feature approximations, but we also report nearly indistinguishable predictive performance when comparing between exact and approximate representations</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2018/comprehensive/">A Comprehensive Study of Activity Recognition Using Accelerometers</a></h2>
      <p class="post-meta">March 19, 2018</p>
      <div class="profile col one left">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2018/comprehensive/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2018/comprehensive/thumb.png" />
  </a>
</div>



        
      </div>
      <p>This paper serves as a survey and empirical evaluation of the state-of-the-art in activity recognition methods using accelerometers. The paper is particularly focused on long-term activity recognition in real-world settings. In these environments, data collection is not a trivial matter; thus, there are performance trade-offs between prediction accuracy, which is not the sole system objective, and keeping the maintenance overhead at minimum levels. We examine research that has focused on the selection of activities, the features that are extracted from the accelerometer data, the segmentation of the time-series data, the locations of accelerometers, the selection and configuration trade-offs, the test/retest reliability, and the generalisation performance.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2017/unsupervised/">Unsupervised learning of sensor topologies for improving activity recognition in smart environments</a></h2>
      <p class="post-meta">April 19, 2017</p>
      <div class="profile col one right">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2017/unsupervised/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2017/unsupervised/thumb.png" />
  </a>
</div>



        
      </div>
      <p>There has been significant recent interest in sensing systems and â€˜smart environmentsâ€™, with a number of longitudinal studies in this area. Typically the goal of these studies is to develop methods to predict, at any one moment of time, the activity or activities that the resident(s) of the home are engaged in, which may in turn be used for determining normal or abnormal patterns of behaviour (e.g. in a health-care setting). Classification algorithms, such as Conditional Random Field (CRFs), typically consider sensor activations as features but these are often treated as if they were independent, which in general they are not. Our hypothesis is that learning patterns based on combinations of sensors will be more powerful than single sensors alone.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2017/probabilistic/">Probabilistic sensor fusion for ambient assisted living</a></h2>
      <p class="post-meta">February 4, 2017</p>
      <div class="profile col one left">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2017/probabilistic/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2017/probabilistic/thumb.png" />
  </a>
</div>



        
      </div>
      <p>There is a widely-accepted need to revise current forms of health-care provision, with particular interest in sensing systems in the home. Given a multiple-modality sensor platform with heterogeneous network connectivity, as is under development in the Sensor Platform for HEalthcare in Residential Environment (SPHERE) Interdisciplinary Research Collaboration (IRC), we face specific challenges relating to the fusion of the heterogeneous sensor modalities. We introduce Bayesian models for sensor fusion, which aims to address the challenges of fusion of heterogeneous sensor modalities. Using this approach we are able to identify the modalities that have most utility for each particular activity, and simultaneously identify which features within that activity are most relevant for a given activity.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2016/bdl/">BDL. NET: Bayesian dictionary learning in Infer. NET</a></h2>
      <p class="post-meta">September 13, 2016</p>
      <div class="profile col one right">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2016/bdl/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2016/bdl/thumb.png" />
  </a>
</div>



        
      </div>
      <p>We introduce and analyse a flexible and efficient implementation of Bayesian dictionary learning for sparse coding. By placing Gaussian-inverse-Gamma hierarchical priors on the coefficients, the model can automatically determine the required sparsity level for good reconstructions, whilst also automatically learning the noise level in the data, obviating the need for heuristic methods for choosing sparsity levels. This model can be solved efficiently using Variational Message Passing (VMP), which we have implemented in the Infer.NET framework for probabilistic programming and inference. We analyse the properties of the model via empirical validation on several accelerometer datasets. We provide source code to replicate all of the experiments in this paper.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2016/need/">On the need for structure modelling in sequence prediction</a></h2>
      <p class="post-meta">September 1, 2016</p>
      <div class="profile col one left">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2016/need/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2016/need/thumb.png" />
  </a>
</div>



        
      </div>
      <p>There is no uniform approach in the literature for modelling sequential correlations in sequence classification problems. It is easy to find examples of unstructured models (e.g. logistic regression) where correlations are not taken into account at all, but there are also many examples where the correlations are explicitly incorporated into aâ€”potentially computationally expensiveâ€”structured classification model (e.g. conditional random fields). In this paper we lay theoretical and empirical foundations for clarifying the types of problem which necessitate direct modelling of correlations in sequences, and the types of problem where unstructured models that capture sequential aspects solely through features are sufficient. The theoretical work in this paper shows that the rate of decay of auto-correlations within a sequence is related to the excess classification risk that is incurred by ignoring the structural aspect of the data.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2016/sphere/">The SPHERE challenge: Activity recognition with multimodal sensor data</a></h2>
      <p class="post-meta">March 2, 2016</p>
      <div class="profile col one right">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2016/sphere/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2016/sphere/thumb.png" />
  </a>
</div>



        
      </div>
      <p>This paper outlines the Sensor Platform for HEalthcare in Residential Environment (SPHERE) project and details the SPHERE challenge that will take place in conjunction with European Conference on Machine Learning and Principles and Practice of Knowledge Discovery (ECML-PKDD) between March and July 2016. The SPHERE challenge is an activity recognition competition where predictions are made from video, accelerometer and environmental sensors. Monetary prizes will be awarded to the top three entrants, with Euro 1,000 being awarded to the winner, Euro 600 being awarded to the first runner up, and Euro 400 being awarded to the second runner up.</p>
    </li>
  
    
    <li>
      <h2><a class="post-title" href="/blog/2015/circular/">Bayesian modelling of the temporal aspects of smart home activity with circular statistics</a></h2>
      <p class="post-meta">September 7, 2015</p>
      <div class="profile col one left">
        
            



<div class='img_row'>
  <a href="http://localhost:4000/assets/2015/circular/thumb.png">
    <img class="col three" src="http://localhost:4000/assets/2015/circular/thumb.png" />
  </a>
</div>



        
      </div>
      <p>Typically, when analysing patterns of activity in a smart home environment, the daily patterns of activity are either ignored completely or summarised into a high-level hour-of-day feature that is then combined with sensor activities. However, when summarising the temporal nature of an activity into a coarse feature such as this, not only is information lost after discretisation, but also the strength of the periodicity of the action is ignored. We propose to model the temporal nature of activities using circular statistics, and in particular by performing Bayesian inference with Wrapped Normal (WN) and WN Mixture (WNM) models. We firstly demonstrate the accuracy of inference on toy data using both Gibbs sampling and Expectation Propagation (EP), and then show the results of the inference on publicly available smart-home data. Such models can be useful for analysis or prediction in their own right, or can be readily combined with larger models incorporating multiple modalities of sensor activity.</p>
    </li>
  
</ul>



<div class="social">
  
    <div class="col three caption">
      Contact me through the links below
    </div>
  
  <span class="contacticon center">
    <a href="mailto:%74%77%6F%6D%65%79%6E%6A %61%74 %67%6D%61%69%6C %64%6F%74 %63%6F%6D"><i class="fas fa-envelope" style="font-size:0.5em;"></i></a>
    <a href="https://orcid.org/0000-0002-3225-2654" style="font-size:0.5em;" target="_blank" title="ORCID"><i class="ai ai-orcid"></i></a>
    <a href="https://scholar.google.com/citations?user=bRN8Y34AAAAJ" style="font-size:0.5em;" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
    <a href="https://github.com/njtwomey" style="font-size:0.5em;" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
    <a href="https://www.linkedin.com/in/nialltwomey" style="font-size:0.5em;" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
    <a href="https://twitter.com/twomeynj" style="font-size:0.5em;" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
    
    
    
  </span>
</div>



      </div>
    </div>

    <footer>

  <div class="wrapper col three caption">
    &copy; Copyright 2019 Niall Twomey
    
    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="http://localhost:4000/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="http://localhost:4000/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
